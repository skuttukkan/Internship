{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b54bf10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all modules\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814fab96",
   "metadata": {},
   "source": [
    "### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "68b8c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e18862c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First get the webpage https://www.shine.com\n",
    "\n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b82b01e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"form-control\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b3dbe2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input')\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "09fc0ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Then click the searchbutton.\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9811e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1ba1014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Scraping job title from the given page\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,\"//h2[@itemprop='name']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,\"//div[@class=' jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "# Scraping experience needed from the given page\n",
    "\n",
    "exp_tags=driver.find_elements(By.XPATH,\"//div[@class=' jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t']\")\n",
    "for i in exp_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "\n",
    "# Scraping company name from the given page\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,\"//div[@class='jobCard_jobCard_cName__mYnow']\")\n",
    "for i in company_tags[0:10]:\n",
    "    name=i.text\n",
    "    company_name.append(name)\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9f1957c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>acme services private limited</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>acme services private limited</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>orcapod consulting services pvt. lt...</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We have requirement for Data Analyst - Associa...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>pricewaterhousecoopers (pwc)</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst-Bangalore</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>acura solutions.</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cloud/D&amp;A/Microsoft/AI - Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>vega intellisoft private limited</td>\n",
       "      <td>4 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Endurance Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>mercede</td>\n",
       "      <td>1 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Consultant - Data Analyst - Data Analytics</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>pylon management consulting</td>\n",
       "      <td>4 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We have requirement for Client Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>5 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Urgent Requirement for Reference Data Analyst ...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title   Job Location  \\\n",
       "0                                       Data Analyst      Bangalore   \n",
       "1                                       Data Analyst      Bangalore   \n",
       "2                                       Data Analyst  Bangalore\\n+1   \n",
       "3  We have requirement for Data Analyst - Associa...      Bangalore   \n",
       "4                             Data Analyst-Bangalore  Bangalore\\n+1   \n",
       "5              Cloud/D&A/Microsoft/AI - Data Analyst      Bangalore   \n",
       "6                             Endurance Data Analyst      Bangalore   \n",
       "7         Consultant - Data Analyst - Data Analytics      Bangalore   \n",
       "8        We have requirement for Client Data Analyst      Bangalore   \n",
       "9  Urgent Requirement for Reference Data Analyst ...      Bangalore   \n",
       "\n",
       "                             Company Name Experience Required  \n",
       "0           acme services private limited          2 to 5 Yrs  \n",
       "1           acme services private limited          2 to 5 Yrs  \n",
       "2  orcapod consulting services pvt. lt...          2 to 4 Yrs  \n",
       "3            pricewaterhousecoopers (pwc)          4 to 6 Yrs  \n",
       "4                        acura solutions.          4 to 6 Yrs  \n",
       "5        vega intellisoft private limited          4 to 8 Yrs  \n",
       "6                                 mercede          1 to 5 Yrs  \n",
       "7             pylon management consulting          4 to 5 Yrs  \n",
       "8                                jpmorgan          5 to 8 Yrs  \n",
       "9                                jpmorgan          2 to 4 Yrs  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Job Title': job_title, 'Job Location': job_location,'Company Name':company_name,'Experience Required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a76dd19",
   "metadata": {},
   "source": [
    "### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2fedda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ce780e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First get the webpage https://www.shine.com\n",
    "\n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0a25e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"form-control\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c77cb277",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input')\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "333e8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Then click the searchbutton.\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f5da316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b2947d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hiring For Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - (BERT, NLP), Kubeflow (or) ML Ops',\n",
       " 'Data Scientist Senior',\n",
       " 'BGSW Sr Data Scientist Template',\n",
       " 'Urgent applicants for Data Scientist for Battery Domain',\n",
       " 'Data Scientist Architect',\n",
       " 'CCB - Risk Data Scientist - Senior Associate',\n",
       " 'Sr Data scientist']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping job title from the given page\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,\"//h2[@itemprop='name']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "print(len(job_title))\n",
    "job_title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "535d4b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Bangalore\\n+15',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore\\n+7',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping job location from the given page\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,\"//div[@class=' jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "print(len(job_location))\n",
    "job_location\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eddc8dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0 to 4 Yrs',\n",
       " '3 to 8 Yrs',\n",
       " '3 to 8 Yrs',\n",
       " '1 to 5 Yrs',\n",
       " '3 to 6 Yrs',\n",
       " '4 to 9 Yrs',\n",
       " '4 to 6 Yrs',\n",
       " '5 to 10 Yrs',\n",
       " '3 to 8 Yrs',\n",
       " '4 to 5 Yrs']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping experience needed from the given page\n",
    "\n",
    "exp_tags=driver.find_elements(By.XPATH,\"//div[@class=' jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t']\")\n",
    "for i in exp_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "\n",
    "print(len(experience_required))\n",
    "experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c872f686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['niharika enterprises',\n",
       " 'acme services private limited',\n",
       " 'acme services private limited',\n",
       " 'gfl recruitment private limited',\n",
       " 'fidelity national information servi...',\n",
       " 'bosch group',\n",
       " 'bosch group',\n",
       " 'fidelity national information servi...',\n",
       " 'jpmorgan',\n",
       " 'schneider electric']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping company name from the given page\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,\"//div[@class='jobCard_jobCard_cName__mYnow']\")\n",
    "for i in company_tags[0:10]:\n",
    "    name=i.text\n",
    "    company_name.append(name)\n",
    "    \n",
    "print(len(company_name))\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "340a4627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b7fc166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "      <td>niharika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>acme services private limited</td>\n",
       "      <td>3 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>acme services private limited</td>\n",
       "      <td>3 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - (BERT, NLP), Kubeflow (or) ML...</td>\n",
       "      <td>Bangalore\\n+7</td>\n",
       "      <td>gfl recruitment private limited</td>\n",
       "      <td>1 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist Senior</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>fidelity national information servi...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BGSW Sr Data Scientist Template</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bosch group</td>\n",
       "      <td>4 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Urgent applicants for Data Scientist for Batte...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bosch group</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist Architect</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>fidelity national information servi...</td>\n",
       "      <td>5 to 10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CCB - Risk Data Scientist - Senior Associate</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>3 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr Data scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>schneider electric</td>\n",
       "      <td>4 to 5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title    Job Location  \\\n",
       "0                          Hiring For Data Scientist  Bangalore\\n+15   \n",
       "1                                     Data Scientist       Bangalore   \n",
       "2                                     Data Scientist       Bangalore   \n",
       "3  Data Scientist - (BERT, NLP), Kubeflow (or) ML...   Bangalore\\n+7   \n",
       "4                              Data Scientist Senior       Bangalore   \n",
       "5                    BGSW Sr Data Scientist Template       Bangalore   \n",
       "6  Urgent applicants for Data Scientist for Batte...       Bangalore   \n",
       "7                           Data Scientist Architect       Bangalore   \n",
       "8       CCB - Risk Data Scientist - Senior Associate       Bangalore   \n",
       "9                                  Sr Data scientist       Bangalore   \n",
       "\n",
       "                             Company Name Experience Required  \n",
       "0                    niharika enterprises          0 to 4 Yrs  \n",
       "1           acme services private limited          3 to 8 Yrs  \n",
       "2           acme services private limited          3 to 8 Yrs  \n",
       "3         gfl recruitment private limited          1 to 5 Yrs  \n",
       "4  fidelity national information servi...          3 to 6 Yrs  \n",
       "5                             bosch group          4 to 9 Yrs  \n",
       "6                             bosch group          4 to 6 Yrs  \n",
       "7  fidelity national information servi...         5 to 10 Yrs  \n",
       "8                                jpmorgan          3 to 8 Yrs  \n",
       "9                      schneider electric          4 to 5 Yrs  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Job Title': job_title, 'Job Location': job_location,'Company Name':company_name,'Experience Required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af5689b",
   "metadata": {},
   "source": [
    "### Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "84979713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c50de155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. first get thewebpage https://www.shine.com/\n",
    "\n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9ec7f5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"form-control\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ad8bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Then click the searchbutton.\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e89e3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "\n",
    "# Clicking on location filter\n",
    "\n",
    "locfil=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div/ul/li[1]/button\")\n",
    "locfil.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0a839f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Delhi\n",
    "\n",
    "del_fil=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[8]/span/label\")\n",
    "del_fil.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8419f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on location filter\n",
    "\n",
    "salfil=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/ul/li[3]\")\n",
    "salfil.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ca3a7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting 3 to 5 lakhs\n",
    "\n",
    "sal_fil=driver.find_element(By.XPATH,\"//html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[3]/span/label\")\n",
    "sal_fil.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b91e7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results click\n",
    "results=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[4]/button[2]\")\n",
    "results.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a4d673de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# 5. Then scrape the data for the first 10 jobs results youget.\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "# Scraping job title from the given page\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,\"//h2[@itemprop='name']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,\"//div[@class=' jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# Scraping experience needed from the given page\n",
    "\n",
    "exp_tags=driver.find_elements(By.XPATH,\"//div[@class=' jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t']\")\n",
    "for i in exp_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    \n",
    "# Scraping company name from the given page\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,\"//div[@class='jobCard_jobCard_cName__mYnow']\")\n",
    "for i in company_tags[0:10]:\n",
    "    name=i.text\n",
    "    company_name.append(name)\n",
    "    \n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3e43c9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Req. For Data Scientist -Reputed Data Analytic...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>seven consultancy</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For Senior Data Scientist-Reputed IT Industry</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>seven consultancy</td>\n",
       "      <td>4 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Req. now Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>seven consultancy</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Req. post for Junior AI Data Scientist-Reputed...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>seven consultancy</td>\n",
       "      <td>1 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>srinsoft technologies</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>target corporation india pvt ltd</td>\n",
       "      <td>1 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mahindra Comviva - Data Scientist</td>\n",
       "      <td>Delhi\\n+2</td>\n",
       "      <td>comviva</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title Job Location  \\\n",
       "0  Req. For Data Scientist -Reputed Data Analytic...        Delhi   \n",
       "1      For Senior Data Scientist-Reputed IT Industry        Delhi   \n",
       "2                            Req. now Data Scientist        Delhi   \n",
       "3  Req. post for Junior AI Data Scientist-Reputed...        Delhi   \n",
       "4                                     Data Scientist    Delhi\\n+6   \n",
       "5                                     Data Scientist    Delhi\\n+6   \n",
       "6                                     Data Scientist        Delhi   \n",
       "7                                  Sr Data Scientist        Delhi   \n",
       "8                  Mahindra Comviva - Data Scientist    Delhi\\n+2   \n",
       "9                                     Data Scientist        Delhi   \n",
       "\n",
       "                       Company Name Experience Required  \n",
       "0                 seven consultancy          2 to 6 Yrs  \n",
       "1                 seven consultancy          4 to 8 Yrs  \n",
       "2                 seven consultancy          3 to 5 Yrs  \n",
       "3                 seven consultancy          1 to 3 Yrs  \n",
       "4                   quiscon biotech           0 to 1 Yr  \n",
       "5                   quiscon biotech          0 to 3 Yrs  \n",
       "6             srinsoft technologies          3 to 5 Yrs  \n",
       "7  target corporation india pvt ltd          1 to 4 Yrs  \n",
       "8                           comviva          2 to 5 Yrs  \n",
       "9               skyleaf consultants          3 to 6 Yrs  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Finally create a dataframe of the scrapeddata.\n",
    "\n",
    "df = pd.DataFrame({'Job Title': job_title, 'Job Location': job_location,'Company Name':company_name,'Experience Required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4091c6",
   "metadata": {},
   "source": [
    "### Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7d389821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "096e7f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fe2fb14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "\n",
    "pdt=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "pdt.send_keys('Sun Glasses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b5ed81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Then click the searchbutton.\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "69d657ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "pdt_des=[]\n",
    "price=[]\n",
    "offer=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8fa0d467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40 38\n"
     ]
    }
   ],
   "source": [
    "# Scraping brand from the given page\n",
    "\n",
    "\n",
    "brand_tags=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "for i in brand_tags[0:40]:\n",
    "    name=i.text\n",
    "    brand.append(name)\n",
    "\n",
    "# Scraping product description from the given page\n",
    "pdt_tags=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "for i in pdt_tags[0:40]:\n",
    "    pdt=i.text\n",
    "    pdt_des.append(pdt)\n",
    "\n",
    "# Scraping price from the given page\n",
    "price_tags=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "for i in price_tags[0:40]:\n",
    "    p=i.text\n",
    "    price.append(p)\n",
    "\n",
    "# Scraping offer from the given page\n",
    "offer_tags=driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']\")\n",
    "for i in offer_tags[0:40]:\n",
    "    o=i.text\n",
    "    offer.append(o)\n",
    "\n",
    "print(len(brand),len(price),len(offer),len(pdt_des)) # Product description has different length as 2 of the items in the website has differetn xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "767c0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unable to use product description as it has different length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a875cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "nxt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f724d2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80 80\n"
     ]
    }
   ],
   "source": [
    "# Scraping brand from the given page\n",
    "\n",
    "brand_tags=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "for i in brand_tags[0:40]:\n",
    "    name=i.text\n",
    "    brand.append(name)\n",
    "\n",
    "\n",
    "# Scraping price from the given page\n",
    "price_tags=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "for i in price_tags[0:40]:\n",
    "    p=i.text\n",
    "    price.append(p)\n",
    "\n",
    "# Scraping offer from the given page\n",
    "offer_tags=driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']\")\n",
    "for i in offer_tags[0:40]:\n",
    "    o=i.text\n",
    "    offer.append(o)\n",
    "\n",
    "print(len(brand),len(price),len(offer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "dcfb79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]\")\n",
    "nxt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b28736fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "brand_tags=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "for i in brand_tags[0:20]:\n",
    "    name=i.text\n",
    "    brand.append(name)\n",
    "\n",
    "\n",
    "# Scraping price from the given page\n",
    "price_tags=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "for i in price_tags[0:20]:\n",
    "    p=i.text\n",
    "    price.append(p)\n",
    "\n",
    "# Scraping offer from the given page\n",
    "offer_tags=driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']\")\n",
    "for i in offer_tags[0:20]:\n",
    "    o=i.text\n",
    "    offer.append(o)\n",
    "\n",
    "print(len(brand),len(price),len(offer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f543daf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹962</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹965</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>₹216</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹213</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹499</td>\n",
       "      <td>44% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹629</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹423</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹779</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>₹195</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹642</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand Price    Offer\n",
       "0    VINCENT CHASE  ₹962  51% off\n",
       "1    VINCENT CHASE  ₹965  51% off\n",
       "2             SRPM  ₹216  83% off\n",
       "3        Elligator  ₹213  64% off\n",
       "4         Fastrack  ₹499  44% off\n",
       "..             ...   ...      ...\n",
       "95  ROZZETTA CRAFT  ₹629  75% off\n",
       "96  ROZZETTA CRAFT  ₹423  78% off\n",
       "97   VINCENT CHASE  ₹779  61% off\n",
       "98          SUNBEE  ₹195  80% off\n",
       "99   VINCENT CHASE  ₹642  67% off\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Finally create a dataframe of the scrapeddata.\n",
    "\n",
    "df = pd.DataFrame({'Brand': brand, 'Price': price,'Offer':offer})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419a59b",
   "metadata": {},
   "source": [
    "### Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "78f3d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ec484474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weblink in the question is invalid, so using a different link\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-14-midnight-128-gb/product-reviews/itm9e6293c322a84?pid=MOBGHWFHECFVMDCX&lid=LSTMOBGHWFHECFVMDCXBOYSND&marketplace=FLIPKART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5b29243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=[]\n",
    "rev_sum=[]\n",
    "full_rev=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4d452977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Scraping rating from the given page\n",
    "\n",
    "rating_tags=driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "for i in rating_tags[0:10]:\n",
    "    rating=i.text\n",
    "    ratings.append(rating)\n",
    "\n",
    "\n",
    "# Scraping review summary from the given page\n",
    "rev_tags=driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "for i in rev_tags[0:20]:\n",
    "    rev=i.text\n",
    "    rev_sum.append(rev)\n",
    "\n",
    "# Scraping full review from the given page\n",
    "frev_tags=driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "for i in frev_tags[0:20]:\n",
    "    revs=i.text\n",
    "    full_rev.append(revs)\n",
    "\n",
    "print(len(ratings),len(rev_sum),len(full_rev)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "5eee3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "9c88d988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "# Scraping rating from the given page\n",
    "\n",
    "rating_tags=driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "for i in rating_tags[0:10]:\n",
    "    rating=i.text\n",
    "    ratings.append(rating)\n",
    "\n",
    "\n",
    "# Scraping review summary from the given page\n",
    "rev_tags=driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "for i in rev_tags[0:20]:\n",
    "    rev=i.text\n",
    "    rev_sum.append(rev)\n",
    "\n",
    "# Scraping full review from the given page\n",
    "frev_tags=driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "for i in frev_tags[0:20]:\n",
    "    revs=i.text\n",
    "    full_rev.append(revs)\n",
    "\n",
    "print(len(ratings),len(rev_sum),len(full_rev)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8eabeb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "65a2c99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30\n"
     ]
    }
   ],
   "source": [
    "# Scraping rating from the given page\n",
    "\n",
    "rating_tags=driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "for i in rating_tags[0:10]:\n",
    "    rating=i.text\n",
    "    ratings.append(rating)\n",
    "\n",
    "\n",
    "# Scraping review summary from the given page\n",
    "rev_tags=driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "for i in rev_tags[0:20]:\n",
    "    rev=i.text\n",
    "    rev_sum.append(rev)\n",
    "\n",
    "# Scraping full review from the given page\n",
    "frev_tags=driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "for i in frev_tags[0:20]:\n",
    "    revs=i.text\n",
    "    full_rev.append(revs)\n",
    "\n",
    "print(len(ratings),len(rev_sum),len(full_rev)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "b3728a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "nxt.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ad24571a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "# Scraping rating from the given page\n",
    "\n",
    "rating_tags=driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "for i in rating_tags[0:10]:\n",
    "    rating=i.text\n",
    "    ratings.append(rating)\n",
    "\n",
    "\n",
    "# Scraping review summary from the given page\n",
    "rev_tags=driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "for i in rev_tags[0:20]:\n",
    "    rev=i.text\n",
    "    rev_sum.append(rev)\n",
    "\n",
    "# Scraping full review from the given page\n",
    "frev_tags=driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "for i in frev_tags[0:20]:\n",
    "    revs=i.text\n",
    "    full_rev.append(revs)\n",
    "\n",
    "print(len(ratings),len(rev_sum),len(full_rev)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "40a0dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "0d7f57ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scraping rating from the given page\n",
    "\n",
    "rating_tags=driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "for i in rating_tags[0:10]:\n",
    "    rating=i.text\n",
    "    ratings.append(rating)\n",
    "\n",
    "\n",
    "# Scraping review summary from the given page\n",
    "rev_tags=driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "for i in rev_tags[0:20]:\n",
    "    rev=i.text\n",
    "    rev_sum.append(rev)\n",
    "\n",
    "# Scraping full review from the given page\n",
    "frev_tags=driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "for i in frev_tags[0:20]:\n",
    "    revs=i.text\n",
    "    full_rev.append(revs)\n",
    "\n",
    "print(len(ratings),len(rev_sum),len(full_rev)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "e83234af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "19105e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 60 60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scraping rating from the given page\n",
    "\n",
    "rating_tags=driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "for i in rating_tags[0:10]:\n",
    "    rating=i.text\n",
    "    ratings.append(rating)\n",
    "\n",
    "\n",
    "# Scraping review summary from the given page\n",
    "rev_tags=driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "for i in rev_tags[0:20]:\n",
    "    rev=i.text\n",
    "    rev_sum.append(rev)\n",
    "\n",
    "# Scraping full review from the given page\n",
    "frev_tags=driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "for i in frev_tags[0:20]:\n",
    "    revs=i.text\n",
    "    full_rev.append(revs)\n",
    "\n",
    "print(len(ratings),len(rev_sum),len(full_rev)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a062b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "90069bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 70 70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scraping rating from the given page\n",
    "\n",
    "rating_tags=driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "for i in rating_tags[0:10]:\n",
    "    rating=i.text\n",
    "    ratings.append(rating)\n",
    "\n",
    "\n",
    "# Scraping review summary from the given page\n",
    "rev_tags=driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "for i in rev_tags[0:20]:\n",
    "    rev=i.text\n",
    "    rev_sum.append(rev)\n",
    "\n",
    "# Scraping full review from the given page\n",
    "frev_tags=driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "for i in frev_tags[0:20]:\n",
    "    revs=i.text\n",
    "    full_rev.append(revs)\n",
    "\n",
    "print(len(ratings),len(rev_sum),len(full_rev)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d20c58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d4c579b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 80 80\n"
     ]
    }
   ],
   "source": [
    "# Scraping rating from the given page\n",
    "\n",
    "rating_tags=driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "for i in rating_tags[0:10]:\n",
    "    rating=i.text\n",
    "    ratings.append(rating)\n",
    "\n",
    "\n",
    "# Scraping review summary from the given page\n",
    "rev_tags=driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "for i in rev_tags[0:20]:\n",
    "    rev=i.text\n",
    "    rev_sum.append(rev)\n",
    "\n",
    "# Scraping full review from the given page\n",
    "frev_tags=driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "for i in frev_tags[0:20]:\n",
    "    revs=i.text\n",
    "    full_rev.append(revs)\n",
    "\n",
    "print(len(ratings),len(rev_sum),len(full_rev)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "69e13958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unable to do till 100 as the length changes due to different xpath for 1 item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0a56491b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Best smart phone under this price range compar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Damn such a great phone. Camera is really good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Excellent smart phone, Good battery backup and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Just awesome!!\\nI switch to iPhone 14 from iPh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Totally in love with my new iphone 14. Battery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4</td>\n",
       "      <td>Really Nice</td>\n",
       "      <td>Nice look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Best in class in all the aspects. Top notch pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Best phone but same as Iphone 13. There is no ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>It's a apple device .. that means you get the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4</td>\n",
       "      <td>Delightful</td>\n",
       "      <td>Thanks Flipkart for this all new iPhone withou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating              Summary  \\\n",
       "0       5            Fabulous!   \n",
       "1       5        Great product   \n",
       "2       5  Best in the market!   \n",
       "3       5            Must buy!   \n",
       "4       5       Classy product   \n",
       "..    ...                  ...   \n",
       "65      4          Really Nice   \n",
       "66      5  Best in the market!   \n",
       "67      5       Simply awesome   \n",
       "68      5            Fabulous!   \n",
       "69      4           Delightful   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Best smart phone under this price range compar...  \n",
       "1   Damn such a great phone. Camera is really good...  \n",
       "2   Excellent smart phone, Good battery backup and...  \n",
       "3   Just awesome!!\\nI switch to iPhone 14 from iPh...  \n",
       "4   Totally in love with my new iphone 14. Battery...  \n",
       "..                                                ...  \n",
       "65                                          Nice look  \n",
       "66  Best in class in all the aspects. Top notch pe...  \n",
       "67  Best phone but same as Iphone 13. There is no ...  \n",
       "68  It's a apple device .. that means you get the ...  \n",
       "69  Thanks Flipkart for this all new iPhone withou...  \n",
       "\n",
       "[70 rows x 3 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Finally create a dataframe of the scrapeddata.\n",
    "\n",
    "df = pd.DataFrame({'Rating': ratings, 'Summary': rev_sum,'Full Review':full_rev})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35cc7a5",
   "metadata": {},
   "source": [
    "### Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "be451ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a4df5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "97ede25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Enter “sneakers” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "\n",
    "pdt=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "pdt.send_keys('sneakers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "885c2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Then click the searchbutton.\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "778c8fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "brand=[]\n",
    "pdt_des=[]\n",
    "price=[]\n",
    "\n",
    "# Scraping brand from the given page\n",
    "\n",
    "\n",
    "brand_tags=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "for i in brand_tags[0:40]:\n",
    "    name=i.text\n",
    "    brand.append(name)\n",
    "\n",
    "# Scraping product description from the given page\n",
    "pdt_tags=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "for i in pdt_tags[0:40]:\n",
    "    pdt=i.text\n",
    "    pdt_des.append(pdt)\n",
    "\n",
    "# Scraping price from the given page\n",
    "price_tags=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "for i in price_tags[0:40]:\n",
    "    p=i.text\n",
    "    price.append(p)\n",
    "\n",
    "\n",
    "print(len(brand),len(price),len(pdt_des)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a8e7f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d40c20e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80 80\n"
     ]
    }
   ],
   "source": [
    "# Scraping brand from the given page\n",
    "\n",
    "\n",
    "brand_tags=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "for i in brand_tags[0:40]:\n",
    "    name=i.text\n",
    "    brand.append(name)\n",
    "\n",
    "# Scraping product description from the given page\n",
    "pdt_tags=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "for i in pdt_tags[0:40]:\n",
    "    pdt=i.text\n",
    "    pdt_des.append(pdt)\n",
    "\n",
    "# Scraping price from the given page\n",
    "price_tags=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "for i in price_tags[0:40]:\n",
    "    p=i.text\n",
    "    price.append(p)\n",
    "\n",
    "\n",
    "print(len(brand),len(price),len(pdt_des)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b6fafdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]\")\n",
    "nxt.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "903f8838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "# Scraping brand from the given page\n",
    "\n",
    "\n",
    "brand_tags=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "for i in brand_tags[0:20]:\n",
    "    name=i.text\n",
    "    brand.append(name)\n",
    "\n",
    "# Scraping product description from the given page\n",
    "pdt_tags=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "for i in pdt_tags[0:20]:\n",
    "    pdt=i.text\n",
    "    pdt_des.append(pdt)\n",
    "\n",
    "# Scraping price from the given page\n",
    "price_tags=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "for i in price_tags[0:20]:\n",
    "    p=i.text\n",
    "    price.append(p)\n",
    "\n",
    "\n",
    "print(len(brand),len(price),len(pdt_des)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "7729b540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Modern Trendy Sneakers boot Sneakers Sneakers ...</td>\n",
       "      <td>₹349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SFR</td>\n",
       "      <td>Mid-Top Combo Pack of 02 Pairs Lace-ups Traine...</td>\n",
       "      <td>₹379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Lightweight,Comfort,Summer,Trendy,Walking,Outd...</td>\n",
       "      <td>₹249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Hustle V2 Sneakers For Men</td>\n",
       "      <td>₹1,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Footox</td>\n",
       "      <td>Sneaker for Mens | Casual Shoes | Men Shoes Sn...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand                                        Description   Price\n",
       "0     Magnolia  Modern Trendy Sneakers boot Sneakers Sneakers ...    ₹349\n",
       "1          SFR  Mid-Top Combo Pack of 02 Pairs Lace-ups Traine...    ₹379\n",
       "2        BIRDE      Combo Pack of 2 Casual Shoes Sneakers For Men    ₹479\n",
       "3         aadi  Lightweight,Comfort,Summer,Trendy,Walking,Outd...    ₹249\n",
       "4         PUMA                         Hustle V2 Sneakers For Men  ₹1,499\n",
       "..         ...                                                ...     ...\n",
       "95    RED TAPE                                   Sneakers For Men    ₹779\n",
       "96    RapidBox                                   Sneakers For Men    ₹549\n",
       "97      Footox  Sneaker for Mens | Casual Shoes | Men Shoes Sn...    ₹399\n",
       "98  HIGHLANDER                                   Sneakers For Men    ₹597\n",
       "99  HIGHLANDER                                   Sneakers For Men    ₹398\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Finally create a dataframe of the scrapeddata.\n",
    "\n",
    "df = pd.DataFrame({'Brand': brand, 'Description': pdt_des,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e7812",
   "metadata": {},
   "source": [
    "### Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop: 1. Title\n",
    "2. Ratings 3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "37c33328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "49474cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to  https://www.amazon.in/ \n",
    "\n",
    "driver.get(\" https://www.amazon.in/ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "5248f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Laptop in Search field\n",
    "\n",
    "item=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "item.send_keys('Laptop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "41e64b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Then click the searchbutton.\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "207faca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set CPU Type filter to “Intel Core i7”\n",
    "cpu=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[6]/span[9]/li/span/a/div/label/i\")\n",
    "cpu.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "e63bb8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "ratings=[]\n",
    "price=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "c48fd2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scraping title from the given page\n",
    "\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in title_tags[0:10]:\n",
    "    t=i.text\n",
    "    title.append(t)\n",
    "\n",
    "# Scraping product ratings from the given page\n",
    "rating=driver.find_elements(By.XPATH,\"//a[@class='a-popover-trigger a-declarative']\")\n",
    "for i in rating[0:10]:\n",
    "    r=i.text\n",
    "    ratings.append(r)\n",
    "\n",
    "# Scraping price from the given page\n",
    "price_tags=driver.find_elements(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "for i in price_tags[0:10]:\n",
    "    p=i.text\n",
    "    price.append(p)\n",
    "\n",
    "\n",
    "print(len(title),len(price),len(ratings)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "1abb909a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...</td>\n",
       "      <td></td>\n",
       "      <td>98,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS TUF Gaming F15 (2023) 90WHr Battery, Inte...</td>\n",
       "      <td></td>\n",
       "      <td>1,15,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Victus Gaming Latest 12th Gen Intel Core i7...</td>\n",
       "      <td></td>\n",
       "      <td>90,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td></td>\n",
       "      <td>84,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td></td>\n",
       "      <td>93,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Envy x360 12th Gen Intel Core i7-13.3 inch(...</td>\n",
       "      <td></td>\n",
       "      <td>1,03,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Acer Predator Helios Neo 16 Gaming Laptop 13th...</td>\n",
       "      <td></td>\n",
       "      <td>1,49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS Vivobook S15 OLED 2022, 15.6\" 39.62 cms F...</td>\n",
       "      <td></td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...</td>\n",
       "      <td></td>\n",
       "      <td>93,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tile Ratings     Price\n",
       "0  Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...            98,990\n",
       "1  ASUS TUF Gaming F15 (2023) 90WHr Battery, Inte...          1,15,990\n",
       "2  HP Victus Gaming Latest 12th Gen Intel Core i7...            90,990\n",
       "3  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...            84,999\n",
       "4  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...            93,990\n",
       "5  HP Envy x360 12th Gen Intel Core i7-13.3 inch(...          1,03,990\n",
       "6  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...            79,990\n",
       "7  Acer Predator Helios Neo 16 Gaming Laptop 13th...          1,49,990\n",
       "8  ASUS Vivobook S15 OLED 2022, 15.6\" 39.62 cms F...            84,990\n",
       "9  ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...            93,990"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Finally create a dataframe of the scrapeddata.\n",
    "\n",
    "df = pd.DataFrame({'Tile': title, 'Ratings': ratings,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d166a26f",
   "metadata": {},
   "source": [
    "### Q8: Write a python program to scrape data for Top 1000 Quotes of All Time. The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/ \n",
    "2. Click on Top Quotes\n",
    "3. Then scrape a) Quote b)Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "a32a222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "be493cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to  https://www.azquotes.com/\n",
    "\n",
    "driver.get(\"https://www.azquotes.com/ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "cfa66a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 3. Then click Top Quotes.\n",
    "\n",
    "top=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div/div[3]/ul/li[5]/a\")\n",
    "top.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "4416ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote=[]\n",
    "author=[]\n",
    "types=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6211cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting below error while trying to do multiple pages hence had to do page by page\n",
    "start = 0\n",
    "end = 10\n",
    "\n",
    "# Scraping rating from the given page\n",
    "\n",
    "for page in range(start,end):\n",
    "    quote_tags=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "    for i in quote_tags[0:100]:\n",
    "        q=i.text\n",
    "        quote.append(q)\n",
    "\n",
    "    \n",
    "    next_button=driver.find_elements(By.XPATH,\"/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[12]/a\")\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "print(len(quote),len(author),len(types)) \n",
    "---------------------------------------------------------------------------\n",
    "AttributeError                            Traceback (most recent call last)\n",
    "/var/folders/zw/zn7l3qn9205frr7dngvck9_40000gn/T/ipykernel_14067/1746834074.py in <module>\n",
    "     12 \n",
    "     13     next_button=driver.find_elements(By.XPATH,\"/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[12]/a\")\n",
    "---> 14     next_button.click()\n",
    "     15     time.sleep(3)\n",
    "     16 \n",
    "\n",
    "AttributeError: 'list' object has no attribute 'click'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "7326fbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scraping quote from the given page\n",
    "\n",
    "\n",
    "quote_tags=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "for i in quote_tags[0:100]:\n",
    "    q=i.text\n",
    "    quote.append(q)\n",
    "\n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in author_tags[0:100]:\n",
    "    a=i.text\n",
    "    author.append(a)\n",
    "    \n",
    "# Scraping type of quote from the given page\n",
    "\n",
    "type_tags=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in type_tags[0:100]:\n",
    "    t=i.text\n",
    "    types.append(t)\n",
    "    \n",
    "print(len(quote),len(author),len(types)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "f7f95b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[12]/a\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "4d57d363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200 200\n"
     ]
    }
   ],
   "source": [
    "# Scraping quote from the given page\n",
    "\n",
    "\n",
    "quote_tags=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "for i in quote_tags[0:100]:\n",
    "    q=i.text\n",
    "    quote.append(q)\n",
    "\n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in author_tags[0:100]:\n",
    "    a=i.text\n",
    "    author.append(a)\n",
    "    \n",
    "# Scraping type of quote from the given page\n",
    "\n",
    "type_tags=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in type_tags[0:100]:\n",
    "    t=i.text\n",
    "    types.append(t)\n",
    "    \n",
    "print(len(quote),len(author),len(types)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "ec24a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "5c498f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300 300\n"
     ]
    }
   ],
   "source": [
    "# Scraping quote from the given page\n",
    "\n",
    "\n",
    "\n",
    "quote_tags=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "for i in quote_tags[0:100]:\n",
    "    q=i.text\n",
    "    quote.append(q)\n",
    "\n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in author_tags[0:100]:\n",
    "    a=i.text\n",
    "    author.append(a)\n",
    "    \n",
    "# Scraping type of quote from the given page\n",
    "\n",
    "type_tags=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in type_tags[0:100]:\n",
    "    t=i.text\n",
    "    types.append(t)\n",
    "    \n",
    "print(len(quote),len(author),len(types)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "d49a8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "95c5bbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 400 400\n"
     ]
    }
   ],
   "source": [
    "# Scraping quote from the given page\n",
    "\n",
    "\n",
    "\n",
    "quote_tags=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "for i in quote_tags[0:100]:\n",
    "    q=i.text\n",
    "    quote.append(q)\n",
    "\n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in author_tags[0:100]:\n",
    "    a=i.text\n",
    "    author.append(a)\n",
    "    \n",
    "# Scraping type of quote from the given page\n",
    "\n",
    "type_tags=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in type_tags[0:100]:\n",
    "    t=i.text\n",
    "    types.append(t)\n",
    "    \n",
    "print(len(quote),len(author),len(types)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "0931704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "0a151597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500 500\n"
     ]
    }
   ],
   "source": [
    "# Scraping quote from the given page\n",
    "\n",
    "\n",
    "\n",
    "quote_tags=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "for i in quote_tags[0:100]:\n",
    "    q=i.text\n",
    "    quote.append(q)\n",
    "\n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in author_tags[0:100]:\n",
    "    a=i.text\n",
    "    author.append(a)\n",
    "    \n",
    "# Scraping type of quote from the given page\n",
    "\n",
    "type_tags=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in type_tags[0:100]:\n",
    "    t=i.text\n",
    "    types.append(t)\n",
    "    \n",
    "print(len(quote),len(author),len(types)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "8aad8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "f2c47ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 600 600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "quote_tags=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "for i in quote_tags[0:100]:\n",
    "    q=i.text\n",
    "    quote.append(q)\n",
    "\n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in author_tags[0:100]:\n",
    "    a=i.text\n",
    "    author.append(a)\n",
    "    \n",
    "# Scraping type of quote from the given page\n",
    "\n",
    "type_tags=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in type_tags[0:100]:\n",
    "    t=i.text\n",
    "    types.append(t)\n",
    "    \n",
    "print(len(quote),len(author),len(types)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "42894f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "d5e006be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 700 700\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "quote_tags=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "for i in quote_tags[0:100]:\n",
    "    q=i.text\n",
    "    quote.append(q)\n",
    "\n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in author_tags[0:100]:\n",
    "    a=i.text\n",
    "    author.append(a)\n",
    "    \n",
    "# Scraping type of quote from the given page\n",
    "\n",
    "type_tags=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in type_tags[0:100]:\n",
    "    t=i.text\n",
    "    types.append(t)\n",
    "    \n",
    "print(len(quote),len(author),len(types)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "cd9e1d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "e02f4dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 800 800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "quote_tags=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "for i in quote_tags[0:100]:\n",
    "    q=i.text\n",
    "    quote.append(q)\n",
    "\n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in author_tags[0:100]:\n",
    "    a=i.text\n",
    "    author.append(a)\n",
    "    \n",
    "# Scraping type of quote from the given page\n",
    "\n",
    "type_tags=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in type_tags[0:100]:\n",
    "    t=i.text\n",
    "    types.append(t)\n",
    "    \n",
    "print(len(quote),len(author),len(types)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "c8246ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "d1f6c9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 900 900\n"
     ]
    }
   ],
   "source": [
    "quote_tags=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "for i in quote_tags[0:100]:\n",
    "    q=i.text\n",
    "    quote.append(q)\n",
    "\n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in author_tags[0:100]:\n",
    "    a=i.text\n",
    "    author.append(a)\n",
    "    \n",
    "# Scraping type of quote from the given page\n",
    "\n",
    "type_tags=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in type_tags[0:100]:\n",
    "    t=i.text\n",
    "    types.append(t)\n",
    "    \n",
    "print(len(quote),len(author),len(types)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "77f92259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on next page\n",
    "\n",
    "nxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "477cb5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "quote_tags=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "for i in quote_tags[0:100]:\n",
    "    q=i.text\n",
    "    quote.append(q)\n",
    "\n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in author_tags[0:100]:\n",
    "    a=i.text\n",
    "    author.append(a)\n",
    "    \n",
    "# Scraping type of quote from the given page\n",
    "\n",
    "type_tags=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in type_tags[0:100]:\n",
    "    t=i.text\n",
    "    types.append(t)\n",
    "    \n",
    "print(len(quote),len(author),len(types)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "36ab9d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote              Author  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                                         Type  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Finally create a dataframe of the scrapeddata.\n",
    "\n",
    "df = pd.DataFrame({'Quote': quote, 'Author': author,'Type':types})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602605fb",
   "metadata": {},
   "source": [
    "### Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "03c33a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "4f758276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "667b8298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First get the webpagehttps://www.jagranjosh.com/\n",
    "\n",
    "driver.get('https://www.jagranjosh.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "3a5637ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Then You have to click on the GK option\n",
    "\n",
    "gk=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[3]/a\")\n",
    "gk.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "09ef9304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Then click on the List of all Prime Ministers of India\n",
    "\n",
    "pm=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a\")\n",
    "pm.click()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "06e96f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sl.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term of Office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964 16 years, 286 days</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964, 13 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966 1 year, 216 days</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 1966 13 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977 11 years, 59 ...</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979   2 year, 126 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980 170 days</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984 4 years, 29...</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989 5 years, 32...</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990 343 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991 223 days</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996 4 years, 330 days</td>\n",
       "      <td>First PM from South India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996 16 days</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997 324 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998   332 days</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004  6 years, 64 days</td>\n",
       "      <td>The first non-congress PM who completed a full...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014    10 years, 4 days</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - 2019</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>30 May 2019- Incumbent</td>\n",
       "      <td>First non-congress PM with two consecutive ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sl.No                         Name     Born-Dead  \\\n",
       "0     1.            Jawahar Lal Nehru   (1889–1964)   \n",
       "1     2.    Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "2     3.          Lal Bahadur Shastri   (1904–1966)   \n",
       "3     4.  Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "4     5.                Indira Gandhi   (1917–1984)   \n",
       "5     6.                Morarji Desai   (1896–1995)   \n",
       "6     7.                 Charan Singh   (1902–1987)   \n",
       "7     8.                Indira Gandhi   (1917–1984)   \n",
       "8     9.                 Rajiv Gandhi   (1944–1991)   \n",
       "9    10.                  V. P. Singh   (1931–2008)   \n",
       "10   11.              Chandra Shekhar   (1927–2007)   \n",
       "11   12.          P. V. Narasimha Rao   (1921–2004)   \n",
       "12   13.         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "13   14.             H. D. Deve Gowda   (born 1933)   \n",
       "14   15.           Inder Kumar Gujral   (1919–2012)   \n",
       "15   16.         Atal Bihari Vajpayee   (1924-2018)   \n",
       "16   17.               Manmohan Singh   (born 1932)   \n",
       "17   18.                Narendra Modi   (born 1950)   \n",
       "18   19.                Narendra Modi   (born 1950)   \n",
       "\n",
       "                                       Term of Office  \\\n",
       "0    15 August 1947 to 27 May 1964 16 years, 286 days   \n",
       "1                 27 May 1964 to 9 June 1964, 13 days   \n",
       "2     9 June 1964 to 11 January 1966 1 year, 216 days   \n",
       "3          11 January 1966 to 24 January 1966 13 days   \n",
       "4   24 January 1966 to 24 March 1977 11 years, 59 ...   \n",
       "5   24 March 1977 to  28 July 1979   2 year, 126 days   \n",
       "6            28 July 1979 to 14 January 1980 170 days   \n",
       "7   14 January 1980 to 31 October 1984 4 years, 29...   \n",
       "8   31 October 1984 to 2 December 1989 5 years, 32...   \n",
       "9        2 December 1989 to 10 November 1990 343 days   \n",
       "10          10 November 1990 to 21 June 1991 223 days   \n",
       "11      21 June 1991 to 16 May 1996 4 years, 330 days   \n",
       "12                 16 May 1996 to 1 June 1996 16 days   \n",
       "13              1 June 1996 to 21 April 1997 324 days   \n",
       "14          21 April 1997 to 19 March 1998   332 days   \n",
       "15     19 March 1998 to 22 May 2004  6 years, 64 days   \n",
       "16     22 May 2004 to 26 May 2014    10 years, 4 days   \n",
       "17                                 26 May 2014 - 2019   \n",
       "18                             30 May 2019- Incumbent   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5   Oldest to become PM (81 years old) and first t...  \n",
       "6             Only PM who did not face the Parliament  \n",
       "7   The first lady who served as PM for the second...  \n",
       "8                Youngest to become PM (40 years old)  \n",
       "9   First PM to step down after a vote of no confi...  \n",
       "10              He belongs to  Samajwadi Janata Party  \n",
       "11                          First PM from South India  \n",
       "12                             PM for shortest tenure  \n",
       "13                          He belongs to  Janata Dal  \n",
       "14                                             ------  \n",
       "15  The first non-congress PM who completed a full...  \n",
       "16                                      First Sikh PM  \n",
       "17  4th Prime Minister of India who served two con...  \n",
       "18  First non-congress PM with two consecutive ten...  "
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Then scrap the mentioned data and make theDataFrame.\n",
    "\n",
    "\n",
    "# Get the page source\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "# Find the table element using appropriate selectors\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Extract the data from the table\n",
    "data = []\n",
    "ata = []\n",
    "for idx, row in enumerate(table.find_all(\"tr\")):\n",
    "    if idx == 0:\n",
    "        continue  # Skip the first row\n",
    "    row_data = []\n",
    "    for cell in row.find_all(\"td\"):\n",
    "        row_data.append(cell.text.strip())\n",
    "    data.append(row_data)\n",
    "\n",
    "    \n",
    "headers = [\"Sl.No\",\"Name\", \"Born-Dead\", \"Term of Office\", \"Remarks\"]\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44a4006",
   "metadata": {},
   "source": [
    "### Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "58274769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "a72f3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Getting website https://www.motor1.com/\n",
    "\n",
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "3e671d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Then You have to type in the search bar ’50 most expensive cars’ \n",
    "\n",
    "top50=driver.find_element(By.XPATH,\"/html/body/div[3]/div[2]/div/div/div[3]/div/div/div/form/input\")\n",
    "top50.send_keys(\"50 most expensive cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "45fe48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Then click the searchbutton.\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[3]/div[2]/div/div/div[3]/div/div/div/form/button[1]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "972aa8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Then click on 50 most expensive cars in the world..\n",
    "\n",
    "link=driver.find_element(By.XPATH,\"/html/body/div[3]/div[9]/div/div[1]/div/div/div[2]/div/div[1]/h3/a\")\n",
    "link.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "8634f805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 1\n"
     ]
    }
   ],
   "source": [
    "# 4. Then scrap the mentioned data and make the dataframe.\n",
    "\n",
    "name=[]\n",
    "price=[]\n",
    "\n",
    "name_tags=driver.find_elements(By.XPATH,\"//h3[@class='subheader']\")\n",
    "for i in name_tags[0:50]:\n",
    "    n=i.text\n",
    "    name.append(n)\n",
    "\n",
    "price_tags=driver.find_elements(By.XPATH,\"/html/body/div[3]/div[7]/div[2]/div[1]/div[2]/div[1]/p[4]/strong\")\n",
    "for i in price_tags[0:50]:\n",
    "    p=i.text\n",
    "    price.append(p)\n",
    "    \n",
    "print(len(name),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "e5e3f068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McLaren Elva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czinger 21C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lotus Evija</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Delage D12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ferrari FXX K Evo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>McLaren Solus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugatti Chiron Profilée</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Car\n",
       "0                     De Tomaso P72\n",
       "1                 Ferrari LaFerrari\n",
       "2                     Pagani Huayra\n",
       "3                      McLaren Elva\n",
       "4                       Czinger 21C\n",
       "5                     Ferrari Monza\n",
       "6                Gordon Murray T.33\n",
       "7                 Koenigsegg Gemera\n",
       "8                       Zenvo TSR-S\n",
       "9                Hennessey Venom F5\n",
       "10                  Bentley Bacalar\n",
       "11    Hispano Suiza Carmen Boulogne\n",
       "12           Bentley Mulliner Batur\n",
       "13                     Deus Vayanne\n",
       "14                      SSC Tuatara\n",
       "15                      Lotus Evija\n",
       "16              Aston Martin Vulcan\n",
       "17                       Delage D12\n",
       "18                McLaren Speedtail\n",
       "19                     Rimac Nevera\n",
       "20                    Pagani Utopia\n",
       "21             Pininfarina Battista\n",
       "22                Ferrari FXX K Evo\n",
       "23               Gordon Murray T.50\n",
       "24             Lamborghini Countach\n",
       "25         Mercedes-AMG Project One\n",
       "26              Aston Martin Victor\n",
       "27      Hennessey Venom F5 Roadster\n",
       "28                 Koenigsegg Jesko\n",
       "29            Aston Martin Valkyrie\n",
       "30        W Motors Lykan Hypersport\n",
       "31                    McLaren Solus\n",
       "32        Pagani Huayra Roadster BC\n",
       "33         Bugatti Chiron Pur Sport\n",
       "34                 Lamborghini Sian\n",
       "35                 Koenigsegg CC850\n",
       "36  Bugatti Chiron Super Sport 300+\n",
       "37               Lamborghini Veneno\n",
       "38                   Bugatti Bolide\n",
       "39                  Bugatti Mistral\n",
       "40              Pagani Huayra Imola\n",
       "41                     Bugatti Divo\n",
       "42              SP Automotive Chaos\n",
       "43                 Pagani Codalunga\n",
       "44         Mercedes-Maybach Exelero\n",
       "45               Bugatti Centodieci\n",
       "46          Bugatti Chiron Profilée\n",
       "47             Rolls-Royce Sweptail\n",
       "48         Bugatti La Voiture Noire\n",
       "49           Rolls-Royce Boat Tail*"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Car': name})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
