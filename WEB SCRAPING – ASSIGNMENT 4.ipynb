{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0cf8b46",
   "metadata": {},
   "source": [
    "### 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details: A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ecdffa7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon â€“ Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[19]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[24]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[25]</td>\n",
       "      <td>Cocomelon â€“ Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[26]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors â€“ Colorful Eggs on a Farm\"[27]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[28]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear â€“ Recipe for Disaster\"[33]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[34]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[35]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[36]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[37]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[38]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[39]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon â€“ Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Thinking Out Loud\"[41]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[42]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[43]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Faded\"[45]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[47]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Girls Like You\"[48]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi â€“ Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"[50]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"[51]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                                  \"Bath Song\"[15]   \n",
       "4    5.                               \"Shape of You\"[16]   \n",
       "5    6.                              \"See You Again\"[19]   \n",
       "6    7.                \"Phonics Song with Two Words\"[24]   \n",
       "7    8.                          \"Wheels on the Bus\"[25]   \n",
       "8    9.                                \"Uptown Funk\"[26]   \n",
       "9   10.  \"Learning Colors â€“ Colorful Eggs on a Farm\"[27]   \n",
       "10  11.                              \"Gangnam Style\"[28]   \n",
       "11  12.   \"Masha and the Bear â€“ Recipe for Disaster\"[33]   \n",
       "12  13.                             \"Dame Tu Cosita\"[34]   \n",
       "13  14.                                     \"Axel F\"[35]   \n",
       "14  15.                                      \"Sugar\"[36]   \n",
       "15  16.                                       \"Roar\"[37]   \n",
       "16  17.                             \"Counting Stars\"[38]   \n",
       "17  18.                                      \"Sorry\"[39]   \n",
       "18  19.                        \"Baa Baa Black Sheep\"[40]   \n",
       "19  20.                          \"Thinking Out Loud\"[41]   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"[42]   \n",
       "21  22.                                 \"Dark Horse\"[43]   \n",
       "22  23.                             \"Lakdi Ki Kathi\"[44]   \n",
       "23  24.                                      \"Faded\"[45]   \n",
       "24  25.                                    \"Perfect\"[46]   \n",
       "25  26.                                 \"Let Her Go\"[47]   \n",
       "26  27.                             \"Girls Like You\"[48]   \n",
       "27  28.          \"Humpty the train on a fruits ride\"[49]   \n",
       "28  29.                                    \"Lean On\"[50]   \n",
       "29  30.                                   \"Bailando\"[51]   \n",
       "\n",
       "                                           Artist        Upload date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  12.85  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.16  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.70  \n",
       "3                      Cocomelon â€“ Nursery Rhymes        May 2, 2018   6.20  \n",
       "4                                      Ed Sheeran   January 30, 2017   6.00  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.89  \n",
       "6                                       ChuChu TV      March 6, 2014   5.30  \n",
       "7                      Cocomelon â€“ Nursery Rhymes       May 24, 2018   5.24  \n",
       "8                                     Mark Ronson  November 19, 2014   4.92  \n",
       "9                                     Miroshka TV  February 27, 2018   4.89  \n",
       "10                                            Psy      July 15, 2012   4.80  \n",
       "11                                     Get Movies   January 31, 2012   4.55  \n",
       "12                                      El Chombo      April 5, 2018   4.35  \n",
       "13                                     Crazy Frog      June 16, 2009   3.91  \n",
       "14                                       Maroon 5   January 14, 2015   3.87  \n",
       "15                                     Katy Perry  September 5, 2013   3.80  \n",
       "16                                    OneRepublic       May 31, 2013   3.79  \n",
       "17                                  Justin Bieber   October 22, 2015   3.66  \n",
       "18                     Cocomelon â€“ Nursery Rhymes      June 25, 2018   3.64  \n",
       "19                                     Ed Sheeran    October 7, 2014   3.60  \n",
       "20                                        Shakira       June 4, 2010   3.59  \n",
       "21                                     Katy Perry  February 20, 2014   3.52  \n",
       "22                                   Jingle Toons      June 14, 2018   3.48  \n",
       "23                                    Alan Walker   December 3, 2015   3.45  \n",
       "24                                     Ed Sheeran   November 9, 2017   3.45  \n",
       "25                                      Passenger      July 25, 2012   3.44  \n",
       "26                                       Maroon 5       May 31, 2018   3.42  \n",
       "27  Kiddiestv Hindi â€“ Nursery Rhymes & Kids Songs   January 26, 2018   3.41  \n",
       "28                                    Major Lazer     March 22, 2015   3.38  \n",
       "29                               Enrique Iglesias     April 11, 2014   3.38  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table by class name\n",
    "table = soup.find(\"table\", {\"class\": \"wikitable sortable\"})\n",
    "\n",
    "if table is None:\n",
    "    print(\"Table not found on the page.\")\n",
    "    exit()  # Terminate the program if the table is not found\n",
    "    \n",
    "ranks = []\n",
    "names = []\n",
    "artists = []\n",
    "upload_dates = []\n",
    "views = []\n",
    "\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    columns = row.find_all(\"td\")\n",
    "\n",
    "    # Add error handling to handle missing columns\n",
    "    try:\n",
    "        rank = columns[0].text.strip()\n",
    "        name = columns[1].text.strip()\n",
    "        artist = columns[2].text.strip()\n",
    "        upload_date = columns[4].text.strip()\n",
    "        view_count = columns[3].text.strip()\n",
    "    except IndexError:\n",
    "        continue  # Skip the row if any column is missing\n",
    "\n",
    "    ranks.append(rank)\n",
    "    names.append(name)\n",
    "    artists.append(artist)\n",
    "    upload_dates.append(upload_date)\n",
    "    views.append(view_count)\n",
    "\n",
    "df=pd.DataFrame({\"Rank\":ranks,\"Name\":names,\"Artist\":artists,\"Upload date\":upload_dates,\"Views\":views})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1cc122",
   "metadata": {},
   "source": [
    "### 2. Scrape the details team Indiaâ€™s international fixtures from bcci.tv. Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "26312e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import all modules\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#Connecting to driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\") \n",
    "\n",
    "# Navigate to website\n",
    "\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "int_button=driver.find_element(By.XPATH,\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\").click()\n",
    "  \n",
    "time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a12fe00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Scraping name from the given page\n",
    "title=[]\n",
    "series=[]\n",
    "place=[]\n",
    "dates=[]\n",
    "time_note=[]\n",
    "\n",
    "try:\n",
    "    title_tags=driver.find_elements(By.XPATH,\"//span[@class='matchOrderText ng-binding ng-scope']\")\n",
    "    for i in title_tags:\n",
    "        title.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    title.append('-')\n",
    "        \n",
    "print(len(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6cfc3f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    series_tags=driver.find_elements(By.XPATH,\"//h5[@class='match-tournament-name ng-binding']\")\n",
    "    for i in series_tags:\n",
    "        series.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    series.append('-')\n",
    "        \n",
    "print(len(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ba9c6252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    place_tags=driver.find_elements(By.XPATH,\"//span[@class='ng-binding ng-scope']\")\n",
    "    for i in place_tags:\n",
    "        place.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    place.append('-')\n",
    "        \n",
    "try:\n",
    "    date_tags=driver.find_elements(By.XPATH,\"//div[@class='match-dates ng-binding']\")\n",
    "    for i in date_tags:\n",
    "        dates.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    dates.append('-')\n",
    "print(len(place),len(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "91715d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    time_tags=driver.find_elements(By.XPATH,\"//div[@class='match-time no-margin ng-binding']\")\n",
    "    for i in time_tags:\n",
    "        time_note.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    time_note.append('-')\n",
    "print(len(time_note))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9beb9464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st Test -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Windsor Park,</td>\n",
       "      <td>12 JUL 2023</td>\n",
       "      <td>3:00 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd Test -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Queen's Park Oval,</td>\n",
       "      <td>20 JUL 2023</td>\n",
       "      <td>3:00 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Kensington Oval,</td>\n",
       "      <td>27 JUL 2023</td>\n",
       "      <td>2:30 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Kensington Oval,</td>\n",
       "      <td>29 JUL 2023</td>\n",
       "      <td>2:30 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Brian Lara Stadium,</td>\n",
       "      <td>1 AUG 2023</td>\n",
       "      <td>2:30 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Brian Lara Stadium,</td>\n",
       "      <td>3 AUG 2023</td>\n",
       "      <td>3:30 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>National Stadium,</td>\n",
       "      <td>6 AUG 2023</td>\n",
       "      <td>3:30 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>National Stadium,</td>\n",
       "      <td>8 AUG 2023</td>\n",
       "      <td>3:30 PM BST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match title                          Series                Place  \\\n",
       "0  1st Test -  INDIA TOUR OF WEST INDIES 2023        Windsor Park,   \n",
       "1  2nd Test -  INDIA TOUR OF WEST INDIES 2023   Queen's Park Oval,   \n",
       "2   1st ODI -  INDIA TOUR OF WEST INDIES 2023     Kensington Oval,   \n",
       "3   2nd ODI -  INDIA TOUR OF WEST INDIES 2023     Kensington Oval,   \n",
       "4   3rd ODI -  INDIA TOUR OF WEST INDIES 2023  Brian Lara Stadium,   \n",
       "5  1st T20I -  INDIA TOUR OF WEST INDIES 2023  Brian Lara Stadium,   \n",
       "6  2nd T20I -  INDIA TOUR OF WEST INDIES 2023    National Stadium,   \n",
       "7  3rd T20I -  INDIA TOUR OF WEST INDIES 2023    National Stadium,   \n",
       "\n",
       "          Date    Time Note  \n",
       "0  12 JUL 2023  3:00 PM BST  \n",
       "1  20 JUL 2023  3:00 PM BST  \n",
       "2  27 JUL 2023  2:30 PM BST  \n",
       "3  29 JUL 2023  2:30 PM BST  \n",
       "4   1 AUG 2023  2:30 PM BST  \n",
       "5   3 AUG 2023  3:30 PM BST  \n",
       "6   6 AUG 2023  3:30 PM BST  \n",
       "7   8 AUG 2023  3:30 PM BST  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Match title\":title,\"Series\":series,\"Place\":place,\"Date\":dates,\"Time Note\":time_note})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b1d649",
   "metadata": {},
   "source": [
    "### 3. Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6872ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all modules\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "\n",
    "#Connecting to driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\") \n",
    "\n",
    "# Navigate to webpage\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "time.sleep(3)\n",
    "try:\n",
    "    cookies = driver.find_element(By.XPATH, \"/html/body/div[1]/div/a\").click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "# Click on the \"Economy\" link in the top menu\n",
    "economy_link = driver.find_element(By.CSS_SELECTOR, \"#top > div.navbar > div:nth-child(2) > button\")\n",
    "economy_link.click()\n",
    "\n",
    "# Click on the \"India\" link in the left menu\n",
    "india_link = driver.find_element(By.CSS_SELECTOR, \"#top > div.navbar > div:nth-child(2) > div > a:nth-child(3)\")\n",
    "india_link.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "181aa589",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Click on the \"GDP of Indian states\" link in the left menu\n",
    "gdp_link = driver.find_element(By.CSS_SELECTOR, \"body > div:nth-child(2) > div:nth-child(5) > div:nth-child(2) > ul > li:nth-child(1) > a\")\n",
    "gdp_link.click()\n",
    "time.sleep(5)\n",
    "try:\n",
    "    agree = driver.find_element(By.XPATH, \"/html/body/div[3]/div/div/div/div[2]/div/button[2]\")\n",
    "    agree.click()\n",
    "except NoSuchElementException:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b7b681c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks=[]\n",
    "states=[]\n",
    "gsdp18_19=[]\n",
    "gsdp19_20=[]\n",
    "share_1819=[]\n",
    "gdp_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "89385575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid number of cells\n"
     ]
    }
   ],
   "source": [
    "# Find the table containing the data\n",
    "table = driver.find_element(By.ID, \"table_id\")\n",
    "\n",
    "# Extract the data from the table\n",
    "rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "for row in rows[1:]:\n",
    "    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    \n",
    "    # Check if the cells list has enough elements\n",
    "    if len(cells) >= 6:\n",
    "        # Extract the data from the cells\n",
    "        rank = cells[0].text\n",
    "        state = cells[1].text\n",
    "        gsdp1819 = cells[2].text\n",
    "        gsdp1920 = cells[3].text\n",
    "        share1819 = cells[4].text\n",
    "        gdp = cells[5].text\n",
    "    \n",
    "        ranks.append(rank)\n",
    "        states.append(state)\n",
    "        gsdp18_19.append(gsdp1819)\n",
    "        gsdp19_20.append(gsdp1920)\n",
    "        share_1819.append(share1819)\n",
    "        gdp_.append(gdp)\n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid number of cells\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "41988168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19) at current prices</th>\n",
       "      <th>GSDP(19-20) at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td>India</td>\n",
       "      <td>20,351,013</td>\n",
       "      <td>18,886,957</td>\n",
       "      <td></td>\n",
       "      <td>2,869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19) at current prices  \\\n",
       "0     1                Maharashtra                             -   \n",
       "1     2                 Tamil Nadu                     1,845,853   \n",
       "2     3              Uttar Pradesh                     1,687,818   \n",
       "3     4                    Gujarat                             -   \n",
       "4     5                  Karnataka                     1,631,977   \n",
       "5     6                West Bengal                     1,253,832   \n",
       "6     7                  Rajasthan                     1,020,989   \n",
       "7     8             Andhra Pradesh                       972,782   \n",
       "8     9                  Telangana                       969,604   \n",
       "9    10             Madhya Pradesh                       906,672   \n",
       "10   11                     Kerala                             -   \n",
       "11   12                      Delhi                       856,112   \n",
       "12   13                    Haryana                       831,610   \n",
       "13   14                      Bihar                       611,804   \n",
       "14   15                     Punjab                       574,760   \n",
       "15   16                     Odisha                       521,275   \n",
       "16   17                      Assam                             -   \n",
       "17   18               Chhattisgarh                       329,180   \n",
       "18   19                  Jharkhand                       328,598   \n",
       "19   20                Uttarakhand                             -   \n",
       "20   21            Jammu & Kashmir                             -   \n",
       "21   22           Himachal Pradesh                       165,472   \n",
       "22   23                        Goa                        80,449   \n",
       "23   24                    Tripura                        55,984   \n",
       "24   25                 Chandigarh                             -   \n",
       "25   26                 Puducherry                        38,253   \n",
       "26   27                  Meghalaya                        36,572   \n",
       "27   28                     Sikkim                        32,496   \n",
       "28   29                    Manipur                        31,790   \n",
       "29   30                   Nagaland                             -   \n",
       "30   31          Arunachal Pradesh                             -   \n",
       "31   32                    Mizoram                        26,503   \n",
       "32   33  Andaman & Nicobar Islands                             -   \n",
       "33                           India                    20,351,013   \n",
       "\n",
       "   GSDP(19-20) at current prices Share(18-19)      GDP  \n",
       "0                      2,632,792       13.94%  399.921  \n",
       "1                      1,630,208        8.63%  247.629  \n",
       "2                      1,584,764        8.39%  240.726  \n",
       "3                      1,502,899        7.96%  228.290  \n",
       "4                      1,493,127        7.91%  226.806  \n",
       "5                      1,089,898        5.77%  165.556  \n",
       "6                        942,586        4.99%  143.179  \n",
       "7                        862,957        4.57%  131.083  \n",
       "8                        861,031        4.56%  130.791  \n",
       "9                        809,592        4.29%  122.977  \n",
       "10                       781,653        4.14%  118.733  \n",
       "11                       774,870        4.10%  117.703  \n",
       "12                       734,163        3.89%  111.519  \n",
       "13                       530,363        2.81%   80.562  \n",
       "14                       526,376        2.79%   79.957  \n",
       "15                       487,805        2.58%   74.098  \n",
       "16                       315,881        1.67%   47.982  \n",
       "17                       304,063        1.61%   46.187  \n",
       "18                       297,204        1.57%   45.145  \n",
       "19                       245,895        1.30%   37.351  \n",
       "20                       155,956        0.83%   23.690  \n",
       "21                       153,845        0.81%   23.369  \n",
       "22                        73,170        0.39%   11.115  \n",
       "23                        49,845        0.26%    7.571  \n",
       "24                        42,114        0.22%    6.397  \n",
       "25                        34,433        0.18%    5.230  \n",
       "26                        33,481        0.18%    5.086  \n",
       "27                        28,723        0.15%    4.363  \n",
       "28                        27,870        0.15%    4.233  \n",
       "29                        27,283        0.14%    4.144  \n",
       "30                        24,603        0.13%    3.737  \n",
       "31                        22,287        0.12%    3.385  \n",
       "32                             -            -        -  \n",
       "33                    18,886,957                 2,869  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Rank\":ranks,\"State\":states,\"GSDP(18-19) at current prices\":gsdp18_19,\"GSDP(19-20) at current prices\": gsdp19_20,\"Share(18-19)\": share_1819,\"GDP\":gdp_})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aabdc6b",
   "metadata": {},
   "source": [
    "### 4. Scrape the details of trending repositories on Github.com. Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "289cf57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all modules\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "\n",
    "#Connecting to driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\") \n",
    "\n",
    "# Navigate to webpage\n",
    "driver.get(\"https://github.com/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "968899d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Click on the \"Open Source\" link in the top menu\n",
    "open_link = driver.find_element(By.CSS_SELECTOR, \"body > div.logged-out.env-production.page-responsive.header-overlay.home-campaign > div.position-relative.js-header-wrapper > header > div > div.HeaderMenu--logged-out.p-responsive.height-fit.position-lg-relative.d-lg-flex.flex-column.flex-auto.pt-7.pb-4.top-0 > div > nav > ul > li:nth-child(3) > button\")\n",
    "open_link.click()\n",
    "\n",
    "# Click on the \"trending\" link in the left menu\n",
    "trending_link = driver.find_element(By.CSS_SELECTOR, \"body > div.logged-out.env-production.page-responsive.header-overlay.home-campaign > div.position-relative.js-header-wrapper > header > div > div.HeaderMenu--logged-out.p-responsive.height-fit.position-lg-relative.d-lg-flex.flex-column.flex-auto.pt-7.pb-4.top-0 > div > nav > ul > li:nth-child(3) > div > div:nth-child(3) > ul > li:nth-child(2) > a\")\n",
    "trending_link.click()\n",
    "\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "de0d7af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stability-AI / generative-models</td>\n",
       "      <td>Generative Models by Stability AI</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sveltejs / svelte</td>\n",
       "      <td>Cybernetically enhanced web apps</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ykdojo / kaguya</td>\n",
       "      <td>A ChatGPT plugin that allows you to load and e...</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chat2db / Chat2DB</td>\n",
       "      <td>ðŸ”¥ ðŸ”¥ ðŸ”¥ An intelligent and versatile general-pur...</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a16z-infra / ai-getting-started</td>\n",
       "      <td>A Javascript AI getting started stack for week...</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>techleadhd / chatgpt-retrieval</td>\n",
       "      <td>Description not found.</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prisma / prisma</td>\n",
       "      <td>Next-generation ORM for Node.js &amp; TypeScript |...</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sindresorhus / awesome</td>\n",
       "      <td>ðŸ˜Ž Awesome lists about all kinds of interesting...</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>Language not found.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>scikit-learn / scikit-learn</td>\n",
       "      <td>scikit-learn: machine learning in Python</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>codecrafters-io / build-your-own-x</td>\n",
       "      <td>Master programming by recreating your favorite...</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>Language not found.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>refinedev / refine</td>\n",
       "      <td>Build your React-based CRUD applications, with...</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>google / googletest</td>\n",
       "      <td>GoogleTest - Google Testing and Mocking Framework</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>geohot / tinygrad</td>\n",
       "      <td>You like pytorch? You like micrograd? You love...</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CASIA-IVA-Lab / FastSAM</td>\n",
       "      <td>Fast Segment Anything</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>unifyai / ivy</td>\n",
       "      <td>Unified AI</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>coollabsio / coolify</td>\n",
       "      <td>An open-source &amp; self-hostable Heroku / Netlif...</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Linen-dev / linen.dev</td>\n",
       "      <td>Lightweight Google-searchable Slack alternativ...</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>eslint / eslint</td>\n",
       "      <td>Find and fix problems in your JavaScript code.</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>terraform-aws-modules / terraform-aws-eks</td>\n",
       "      <td>Terraform module to create an Elastic Kubernet...</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>HCL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MustardChef / WSABuilds</td>\n",
       "      <td>Run Windows Subsystem For Android on your Wind...</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>joamag / boytacean</td>\n",
       "      <td>A GB emulator that is written in Rust ðŸ¦€!</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>angular / angular</td>\n",
       "      <td>The modern web developerâ€™s platform</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sveltejs / kit</td>\n",
       "      <td>web development, streamlined</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ventoy / Ventoy</td>\n",
       "      <td>A new bootable USB solution.</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sebastianbergmann / phpunit</td>\n",
       "      <td>The PHP Unit Testing framework.</td>\n",
       "      <td>Contributors count not found.</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title  \\\n",
       "0            Stability-AI / generative-models   \n",
       "1                           sveltejs / svelte   \n",
       "2                             ykdojo / kaguya   \n",
       "3                           chat2db / Chat2DB   \n",
       "4             a16z-infra / ai-getting-started   \n",
       "5              techleadhd / chatgpt-retrieval   \n",
       "6                             prisma / prisma   \n",
       "7                      sindresorhus / awesome   \n",
       "8                 scikit-learn / scikit-learn   \n",
       "9          codecrafters-io / build-your-own-x   \n",
       "10                         refinedev / refine   \n",
       "11                        google / googletest   \n",
       "12                          geohot / tinygrad   \n",
       "13                    CASIA-IVA-Lab / FastSAM   \n",
       "14                              unifyai / ivy   \n",
       "15                       coollabsio / coolify   \n",
       "16                      Linen-dev / linen.dev   \n",
       "17                            eslint / eslint   \n",
       "18  terraform-aws-modules / terraform-aws-eks   \n",
       "19                    MustardChef / WSABuilds   \n",
       "20                         joamag / boytacean   \n",
       "21                          angular / angular   \n",
       "22                             sveltejs / kit   \n",
       "23                            ventoy / Ventoy   \n",
       "24                sebastianbergmann / phpunit   \n",
       "\n",
       "                                          Description  \\\n",
       "0                   Generative Models by Stability AI   \n",
       "1                    Cybernetically enhanced web apps   \n",
       "2   A ChatGPT plugin that allows you to load and e...   \n",
       "3   ðŸ”¥ ðŸ”¥ ðŸ”¥ An intelligent and versatile general-pur...   \n",
       "4   A Javascript AI getting started stack for week...   \n",
       "5                              Description not found.   \n",
       "6   Next-generation ORM for Node.js & TypeScript |...   \n",
       "7   ðŸ˜Ž Awesome lists about all kinds of interesting...   \n",
       "8            scikit-learn: machine learning in Python   \n",
       "9   Master programming by recreating your favorite...   \n",
       "10  Build your React-based CRUD applications, with...   \n",
       "11  GoogleTest - Google Testing and Mocking Framework   \n",
       "12  You like pytorch? You like micrograd? You love...   \n",
       "13                              Fast Segment Anything   \n",
       "14                                         Unified AI   \n",
       "15  An open-source & self-hostable Heroku / Netlif...   \n",
       "16  Lightweight Google-searchable Slack alternativ...   \n",
       "17     Find and fix problems in your JavaScript code.   \n",
       "18  Terraform module to create an Elastic Kubernet...   \n",
       "19  Run Windows Subsystem For Android on your Wind...   \n",
       "20           A GB emulator that is written in Rust ðŸ¦€!   \n",
       "21                The modern web developerâ€™s platform   \n",
       "22                       web development, streamlined   \n",
       "23                       A new bootable USB solution.   \n",
       "24                    The PHP Unit Testing framework.   \n",
       "\n",
       "               Contributors Count             Language  \n",
       "0   Contributors count not found.               Python  \n",
       "1   Contributors count not found.           JavaScript  \n",
       "2   Contributors count not found.           JavaScript  \n",
       "3   Contributors count not found.                 Java  \n",
       "4   Contributors count not found.           TypeScript  \n",
       "5   Contributors count not found.               Python  \n",
       "6   Contributors count not found.           TypeScript  \n",
       "7   Contributors count not found.  Language not found.  \n",
       "8   Contributors count not found.               Python  \n",
       "9   Contributors count not found.  Language not found.  \n",
       "10  Contributors count not found.           TypeScript  \n",
       "11  Contributors count not found.                  C++  \n",
       "12  Contributors count not found.               Python  \n",
       "13  Contributors count not found.               Python  \n",
       "14  Contributors count not found.               Python  \n",
       "15  Contributors count not found.                  PHP  \n",
       "16  Contributors count not found.           TypeScript  \n",
       "17  Contributors count not found.           JavaScript  \n",
       "18  Contributors count not found.                  HCL  \n",
       "19  Contributors count not found.                Shell  \n",
       "20  Contributors count not found.                 Rust  \n",
       "21  Contributors count not found.           TypeScript  \n",
       "22  Contributors count not found.           JavaScript  \n",
       "23  Contributors count not found.                    C  \n",
       "24  Contributors count not found.                  PHP  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Find all the repository cards on the page\n",
    "repo_cards = driver.find_elements(By.XPATH, '//article[@class=\"Box-row\"]')\n",
    "\n",
    "# Initialize lists to store the data\n",
    "titles = []\n",
    "descriptions = []\n",
    "contributors_counts = []\n",
    "languages = []\n",
    "\n",
    "# Iterate over each repository card and extract the details\n",
    "for card in repo_cards:\n",
    "    # Find the repository title\n",
    "    title_element = card.find_element(By.XPATH,'.//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "    title = title_element.text.strip()\n",
    "    titles.append(title)\n",
    "\n",
    "    # Find the repository description\n",
    "    try:\n",
    "        description_element = card.find_element(By.TAG_NAME, 'p')\n",
    "        description = description_element.text.strip()\n",
    "        descriptions.append(description)\n",
    "    except NoSuchElementException:\n",
    "        descriptions.append(\"Description not found.\")\n",
    "\n",
    "    # Find the contributors count\n",
    "    try:\n",
    "        contributors_element = card.find_element(By.XPATH, './/a[contains(@href, \"/network/members\")]')\n",
    "        contributors = contributors_element.text.strip()\n",
    "        contributors_counts.append(contributors)\n",
    "    except NoSuchElementException:\n",
    "        contributors_counts.append(\"Contributors count not found.\")\n",
    "\n",
    "    # Find the language used\n",
    "    try:\n",
    "        language_element = card.find_element(By.XPATH, './/span[@itemprop=\"programmingLanguage\"]')\n",
    "        language = language_element.text.strip()\n",
    "        languages.append(language)\n",
    "    except NoSuchElementException:\n",
    "        languages.append(\"Language not found.\")\n",
    "\n",
    "# Create a dataframe from the extracted data\n",
    "data = {\n",
    "    \"Title\": titles,\n",
    "    \"Description\": descriptions,\n",
    "    \"Contributors Count\": contributors_counts,\n",
    "    \"Language\": languages\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8787b4fd",
   "metadata": {},
   "source": [
    "### 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artistname\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "3953c5a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[5]/div[2]/div/div/div[2]/div/div/button[2]\"}\n  (Session info: chrome=114.0.5735.133)\nStacktrace:\n0   chromedriver                        0x000000010d9ed6b8 chromedriver + 4937400\n1   chromedriver                        0x000000010d9e4b73 chromedriver + 4901747\n2   chromedriver                        0x000000010d5a2616 chromedriver + 435734\n3   chromedriver                        0x000000010d5e5e0f chromedriver + 712207\n4   chromedriver                        0x000000010d5e60a1 chromedriver + 712865\n5   chromedriver                        0x000000010d6279a4 chromedriver + 981412\n6   chromedriver                        0x000000010d60a03d chromedriver + 860221\n7   chromedriver                        0x000000010d624e76 chromedriver + 970358\n8   chromedriver                        0x000000010d609de3 chromedriver + 859619\n9   chromedriver                        0x000000010d5d7d7f chromedriver + 654719\n10  chromedriver                        0x000000010d5d90de chromedriver + 659678\n11  chromedriver                        0x000000010d9a92ad chromedriver + 4657837\n12  chromedriver                        0x000000010d9ae130 chromedriver + 4677936\n13  chromedriver                        0x000000010d9b4def chromedriver + 4705775\n14  chromedriver                        0x000000010d9af05a chromedriver + 4681818\n15  chromedriver                        0x000000010d98192c chromedriver + 4495660\n16  chromedriver                        0x000000010d9cc838 chromedriver + 4802616\n17  chromedriver                        0x000000010d9cc9b7 chromedriver + 4802999\n18  chromedriver                        0x000000010d9dd99f chromedriver + 4872607\n19  libsystem_pthread.dylib             0x00007fff734c8109 _pthread_start + 148\n20  libsystem_pthread.dylib             0x00007fff734c3b8b thread_start + 15\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zw/zn7l3qn9205frr7dngvck9_40000gn/T/ipykernel_17416/63746465.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#Accept cookies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcookies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/html/body/div[5]/div[2]/div/div/div[2]/div/div/button[2]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Click on the Charts option\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'[name=\"{value}\"]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFIND_ELEMENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"using\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[5]/div[2]/div/div/div[2]/div/div/button[2]\"}\n  (Session info: chrome=114.0.5735.133)\nStacktrace:\n0   chromedriver                        0x000000010d9ed6b8 chromedriver + 4937400\n1   chromedriver                        0x000000010d9e4b73 chromedriver + 4901747\n2   chromedriver                        0x000000010d5a2616 chromedriver + 435734\n3   chromedriver                        0x000000010d5e5e0f chromedriver + 712207\n4   chromedriver                        0x000000010d5e60a1 chromedriver + 712865\n5   chromedriver                        0x000000010d6279a4 chromedriver + 981412\n6   chromedriver                        0x000000010d60a03d chromedriver + 860221\n7   chromedriver                        0x000000010d624e76 chromedriver + 970358\n8   chromedriver                        0x000000010d609de3 chromedriver + 859619\n9   chromedriver                        0x000000010d5d7d7f chromedriver + 654719\n10  chromedriver                        0x000000010d5d90de chromedriver + 659678\n11  chromedriver                        0x000000010d9a92ad chromedriver + 4657837\n12  chromedriver                        0x000000010d9ae130 chromedriver + 4677936\n13  chromedriver                        0x000000010d9b4def chromedriver + 4705775\n14  chromedriver                        0x000000010d9af05a chromedriver + 4681818\n15  chromedriver                        0x000000010d98192c chromedriver + 4495660\n16  chromedriver                        0x000000010d9cc838 chromedriver + 4802616\n17  chromedriver                        0x000000010d9cc9b7 chromedriver + 4802999\n18  chromedriver                        0x000000010d9dd99f chromedriver + 4872607\n19  libsystem_pthread.dylib             0x00007fff734c8109 _pthread_start + 148\n20  libsystem_pthread.dylib             0x00007fff734c3b8b thread_start + 15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# Set up the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the Billboard website\n",
    "driver.get(\"https://www.billboard.com/\")\n",
    "\n",
    "time.sleep(3)\n",
    "#Accept cookies\n",
    "cookies = driver.find_element(By.XPATH,\"/html/body/div[5]/div[2]/div/div/div[2]/div/div/button[2]\").click()\n",
    "\n",
    "# Click on the Charts option\n",
    "charts_option = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a\")))\n",
    "charts_option.click()\n",
    "\n",
    "# Click on the Hot 100 page link\n",
    "hot_100_page_link = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//a[contains(@href, '/charts/hot-100')]\")))\n",
    "hot_100_page_link.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Find the song rows\n",
    "song_rows = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]')\n",
    "\n",
    "# Initialize lists to store the data\n",
    "rank=[]\n",
    "song_names = []\n",
    "artist_names = []\n",
    "last_week_ranks = []\n",
    "peak_ranks = []\n",
    "weeks_on_board_list = []\n",
    "\n",
    "# Iterate over each song row and extract the details\n",
    "for row in song_rows:\n",
    "    \n",
    "    ranking=row.find_element(By.XPATH,\"//span[@class='c-label  a-font-primary-bold-l u-font-size-32@tablet u-letter-spacing-0080@tablet']\").text\n",
    "    rank.append(ranking)\n",
    "    # Extract the song name\n",
    "    song_name = row.find_element(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only']\").text\n",
    "    song_names.append(song_name)\n",
    "\n",
    "    # Extract the artist name\n",
    "    artist_name = row.find_element(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\").text\n",
    "    artist_names.append(artist_name)\n",
    "\n",
    "     # Extract the last week's rank\n",
    "    last_week_rank = row.find_element(By.CLASS_NAME,\"chart-element__metas__left\").text\n",
    "    last_week_ranks.append(last_week_rank)\n",
    "\n",
    "    # Extract the peak rank\n",
    "    peak_rank = row.find_element(By.CLASS_NAME,\"chart-element__rank__number\").text\n",
    "    peak_ranks.append(peak_rank)\n",
    "\n",
    "    # Extract the weeks on the board\n",
    "    weeks_on_board = row.find_element(By.CLASS_NAME,\"chart-element__metas__right\").text\n",
    "    weeks_on_board_list.append(weeks_on_board)\n",
    "    \n",
    "    \n",
    "\n",
    "# Create a dataframe from the scraped data\n",
    "data = {\n",
    "    \"Rank\":rank,\n",
    "    \"Song\": song_names,\n",
    "    \"Artist\": artist_names,\n",
    "    \"Last Week's Rank\": last_week_ranks,\n",
    "    \"Peak Rank\": peak_ranks,\n",
    "    \"Weeks on Board\": weeks_on_board_list\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4eb6bd",
   "metadata": {},
   "source": [
    "### 6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey- compare\n",
    "You have to find the following details:\n",
    "A) Book name B) Author name C) Volumes sold D) Publisher\n",
    "E) Genre   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9aad6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# Set up the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2822114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid number of cells\n",
      "Invalid number of cells\n"
     ]
    }
   ],
   "source": [
    "book_name = []\n",
    "author = []\n",
    "volumes_sold = []\n",
    "publisher = []\n",
    "genre = []\n",
    "\n",
    "# Find the table containing the data\n",
    "table = driver.find_element(By.XPATH, '//table[@class=\"in-article sortable\"]')\n",
    "\n",
    "# Extract the data from the table\n",
    "rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "for row in rows:\n",
    "    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    \n",
    "    # Check if the cells list has enough elements\n",
    "    if len(cells) >= 6:\n",
    "        # Extract the data from the cells\n",
    "        bookname = cells[1].text\n",
    "        auth = cells[2].text\n",
    "        volumes = cells[3].text\n",
    "        publish = cells[4].text\n",
    "        gen = cells[5].text\n",
    "    \n",
    "        book_name.append(bookname)\n",
    "        author.append(auth)\n",
    "        volumes_sold.append(volumes)\n",
    "        publisher.append(publish)\n",
    "        genre.append(gen)\n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid number of cells\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc7e8f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold publisher                        Genre  \n",
       "0     5,094,805   Penguin  Crime, Thriller & Adventure  \n",
       "1     4,475,152   Penguin           Children's Fiction  \n",
       "2     4,200,654   Penguin           Children's Fiction  \n",
       "3     4,179,479   Penguin           Children's Fiction  \n",
       "4     3,758,936   Penguin              Romance & Sagas  \n",
       "..          ...       ...                          ...  \n",
       "95      807,311   Penguin   General & Literary Fiction  \n",
       "96      794,201   Penguin        Food & Drink: General  \n",
       "97      792,187   Penguin          Young Adult Fiction  \n",
       "98      791,507   Penguin           Biography: General  \n",
       "99      791,095   Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from the scraped data\n",
    "data = {\n",
    "    \"Book Name\": book_name,\n",
    "    \"Author\": author,\n",
    "    \"Volumes sold\": volumes_sold,\n",
    "    \"publisher\": publish,\n",
    "    \"Genre\": genre\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb7deb",
   "metadata": {},
   "source": [
    "### 7. Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details: A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time E) Ratings F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a7dfdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# Set up the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d8bd38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]')\n",
    "\n",
    "name=[]\n",
    "year=[]\n",
    "genre=[]\n",
    "run_time=[]\n",
    "ratings=[]\n",
    "votes=[]\n",
    "\n",
    "for row in rows:\n",
    "    name_element = row.find_element(By.XPATH,'.//h3[@class=\"lister-item-header\"]')\n",
    "    name.append(name_element.text)\n",
    "\n",
    "\n",
    "    year_element = row.find_element(By.XPATH,'.//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "    year.append(year_element.text)\n",
    "\n",
    "\n",
    "    genre_element = row.find_element(By.XPATH,'.//span[@class=\"genre\"]')\n",
    "    genre.append(genre_element.text)\n",
    "    \n",
    "    run_element = row.find_element(By.XPATH,'.//span[@class=\"runtime\"]')\n",
    "    run_time.append(run_element.text)\n",
    "    \n",
    "    rate_element = row.find_element(By.XPATH,'.//span[@class=\"ipl-rating-star__rating\"]')\n",
    "    ratings.append(rate_element.text)\n",
    "\n",
    "    vote_element = row.find_element(By.XPATH,'.//span[@name=\"nv\"]')\n",
    "    votes.append(vote_element.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec800237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run TIme</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones (2011â€“2019)</td>\n",
       "      <td>(2011â€“2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>2,174,501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Stranger Things (2016â€“2024)</td>\n",
       "      <td>(2016â€“2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>1,252,254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Walking Dead (2010â€“2022)</td>\n",
       "      <td>(2010â€“2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>1,032,853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. 13 Reasons Why (2017â€“2020)</td>\n",
       "      <td>(2017â€“2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>303,677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The 100 (2014â€“2020)</td>\n",
       "      <td>(2014â€“2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>262,834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96. Reign (2013â€“2017)</td>\n",
       "      <td>(2013â€“2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>51,982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97. A Series of Unfortunate Events (2017â€“2019)</td>\n",
       "      <td>(2017â€“2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>64,011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98. Criminal Minds (2005â€“ )</td>\n",
       "      <td>(2005â€“ )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>208,605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99. Scream: The TV Series (2015â€“2019)</td>\n",
       "      <td>(2015â€“2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>43,408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100. The Haunting of Hill House (2018)</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>260,352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Name         Year  \\\n",
       "0                   1. Game of Thrones (2011â€“2019)  (2011â€“2019)   \n",
       "1                   2. Stranger Things (2016â€“2024)  (2016â€“2024)   \n",
       "2                  3. The Walking Dead (2010â€“2022)  (2010â€“2022)   \n",
       "3                    4. 13 Reasons Why (2017â€“2020)  (2017â€“2020)   \n",
       "4                           5. The 100 (2014â€“2020)  (2014â€“2020)   \n",
       "..                                             ...          ...   \n",
       "95                           96. Reign (2013â€“2017)  (2013â€“2017)   \n",
       "96  97. A Series of Unfortunate Events (2017â€“2019)  (2017â€“2019)   \n",
       "97                     98. Criminal Minds (2005â€“ )     (2005â€“ )   \n",
       "98           99. Scream: The TV Series (2015â€“2019)  (2015â€“2019)   \n",
       "99          100. The Haunting of Hill House (2018)       (2018)   \n",
       "\n",
       "                       Genre Run TIme      Votes  \n",
       "0   Action, Adventure, Drama   57 min  2,174,501  \n",
       "1     Drama, Fantasy, Horror   51 min  1,252,254  \n",
       "2    Drama, Horror, Thriller   44 min  1,032,853  \n",
       "3   Drama, Mystery, Thriller   60 min    303,677  \n",
       "4     Drama, Mystery, Sci-Fi   43 min    262,834  \n",
       "..                       ...      ...        ...  \n",
       "95                     Drama   42 min     51,982  \n",
       "96  Adventure, Comedy, Drama   50 min     64,011  \n",
       "97     Crime, Drama, Mystery   42 min    208,605  \n",
       "98      Comedy, Crime, Drama   45 min     43,408  \n",
       "99    Drama, Horror, Mystery  572 min    260,352  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\":name,\n",
    "    \"Year\": year,\n",
    "    \"Genre\": genre,\n",
    "    \"Run TIme\": run_time,\n",
    "    \"Votes\": votes\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd959e",
   "metadata": {},
   "source": [
    "### 8. Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name B) Data type\n",
    "C) Task\n",
    "D) Attribute type E) No of instances F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "960e98cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# Set up the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "dataset=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]\").click()\n",
    "  \n",
    "time.sleep(3)\n",
    "expand=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "32ec8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = driver.find_elements(By.XPATH,'//div[@class=\"rounded-box bg-base-100\"]')\n",
    "\n",
    "name=[]\n",
    "dtype=[]\n",
    "atype=[]\n",
    "task=[]\n",
    "inst=[]\n",
    "attr=[]\n",
    "year=[]\n",
    "\n",
    "for row in rows:\n",
    "    name_element = row.find_element(By.XPATH,'.//h2[@class=\"truncate text-primary\"]')\n",
    "    name.append(name_element.text)\n",
    "\n",
    "    parent_element = row.find_element(By.CLASS_NAME, \"my-2.hidden.gap-4.md\\\\:grid.grid-cols-12\")\n",
    "\n",
    "    child_elements = parent_element.find_elements(By.TAG_NAME, \"div\")\n",
    "\n",
    "    for i in range(4):\n",
    "        dtype_element = child_elements[1].text\n",
    "        task_element = child_elements[0].text\n",
    "        inst_element = child_elements[2].text\n",
    "        attr_element = child_elements[3].text\n",
    "    \n",
    "    attr.append(attr_element)\n",
    "    inst.append(inst_element)\n",
    "    dtype.append(dtype_element)\n",
    "    task.append(task_element)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8626c22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>No. of instances</th>\n",
       "      <th>No. of attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wine</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name Data Type            Task  \\\n",
       "0                                  Iris            Classification   \n",
       "1                         Heart Disease            Classification   \n",
       "2                                 Adult            Classification   \n",
       "3                      Dry Bean Dataset            Classification   \n",
       "4                              Diabetes                             \n",
       "5            Rice (Cammeo and Osmancik)            Classification   \n",
       "6                                  Wine            Classification   \n",
       "7                        Car Evaluation            Classification   \n",
       "8  Breast Cancer Wisconsin (Diagnostic)            Classification   \n",
       "9                              Mushroom            Classification   \n",
       "\n",
       "  No. of instances No. of attributes  \n",
       "0     Multivariate                    \n",
       "1     Multivariate                    \n",
       "2     Multivariate                    \n",
       "3     Multivariate                    \n",
       "4                                     \n",
       "5     Multivariate                    \n",
       "6     Multivariate                    \n",
       "7     Multivariate                    \n",
       "8     Multivariate                    \n",
       "9     Multivariate                    "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\":name,\n",
    "    \"Data Type\": dtype,\n",
    "    \"Task\": task,\n",
    "    \"No. of instances\":inst,\n",
    "    \"No. of attributes\":attr,\n",
    "    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efb608",
   "metadata": {},
   "source": [
    "### Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company\n",
    "D)Skills they hire for E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e4625128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# Set up the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "driver.get(\"https://www.naukri.com/hr-recruiters-consultants\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#Accept cookies\n",
    "cookies = driver.find_element(By.XPATH,\"//html/body/div/div[4]/div[2]/div/button\").click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "482daa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = driver.find_elements(By.XPATH,'//div[@class=\"rounded-box bg-base-100\"]')\n",
    "\n",
    "exp=[]\n",
    "des=[]\n",
    "skills=[]\n",
    "location=[]\n",
    "com=[]\n",
    "\n",
    "for row in rows:\n",
    "    exp_element = row.find_element(By.XPATH,'.//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "    exp.append(exp_element.text)\n",
    "    \n",
    "    des_element = row.find_element(By.XPATH,'.//a[@class=\"title ellipsis\"]')\n",
    "    des.append(des_element.text)\n",
    "    \n",
    "    com_element = row.find_element(By.XPATH,'.//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "    com.append(com_element.text)\n",
    "    \n",
    "    skills_element = row.find_element(By.XPATH,'.//ul[@class=\"tags has-description\"]')\n",
    "    skills.append(skills_element.text)\n",
    "    \n",
    "    location_element = row.find_element(By.XPATH,'.//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "    location.append(location_element.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b6cdbc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Designation, Company, Experience, Skills, Location]\n",
       "Index: []"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Designation\":des,\n",
    "    \"Company\":com,\n",
    "    \"Experience\": exp,\n",
    "    \"Skills\": skills,\n",
    "    \"Location\":location\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8195325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
